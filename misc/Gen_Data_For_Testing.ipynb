{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Converts output of OpenPose (.json) to a .txt file\n",
    "## Part 1.1 Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import glob, os\n",
    "import numpy as np\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. 2 Extract Keypoints\n",
    "Extract x, y co-ordinates for all pose keypoints and all frames. **This code can handle only one video at a time i.e. keypoints from one test video can be used per run.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BV SAMEER KUMAR\\Documents\\JupterNotebookCodes\\output\n"
     ]
    }
   ],
   "source": [
    "# Change the data path where all the .json files are\n",
    "data_path = r\"data/MHAD/Test/\"\n",
    "os.chdir(data_path)\n",
    "print(os.getcwd())\n",
    "\n",
    "kps = []\n",
    "openpose_2person_count = 0\n",
    "\n",
    "for file in sorted(glob.glob(\"*.json\")):\n",
    "    with open(file) as data_file: \n",
    "        data = json.load(data_file)\n",
    "        if len(data[\"people\"]) > 1:\n",
    "            pprint(\"More than one detection in file, check the noise:\")\n",
    "            openpose_2person_count += 1\n",
    "            print(file)\n",
    "        frame_kps = []\n",
    "        pose_keypoints = data[\"people\"][0][\"pose_keypoints_2d\"]\n",
    "        j = 0\n",
    "        for i in range(36):\n",
    "            frame_kps.append(pose_keypoints[j])\n",
    "            j += 1\n",
    "            if (j+1)%3 == 0:\n",
    "                j += 1\n",
    "        kps.append(frame_kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 36)\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the data\n",
    "kps_np = np.array(kps)\n",
    "print(kps_np.shape)\n",
    "print(len(kps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check how many frames contained more than 1 person \n",
    "print(openpose_2person_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.3 Create a .txt file\n",
    "Write all the data into a .txt file. Each row indicates all the frames that were extracted, and in each row we will have 36 entries corresponding to x, y postions for all 18 keypoints (joints). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data path where .txt file will be store for testing\n",
    "data_path = r\"data/MHAD/database/\"\n",
    "os.chdir(data_path)\n",
    "print(os.getcwd())\n",
    "\n",
    "file_name = \"testvid_\" + str(date.today()) + \".txt\"\n",
    "with open(file_name, \"w\") as text_file:\n",
    "    for i in range(len(kps)):\n",
    "        for j in range(36):\n",
    "            text_file.write('{}'.format(kps[i][j]))\n",
    "            if j < 35:\n",
    "                text_file.write(',')\n",
    "        text_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Convert .txt file into a testing data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_steps depends on rate of video and window_width to be used\n",
    "# in this case camera was 22Hz and a window_width of 1.5s was wanted, giving 22*1.5 = 33\n",
    "num_steps = 32\n",
    "overlap = 0.8125 # 0 = 0% overlap, 1 = 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for file in sorted(glob.glob(\"*.txt\")):\n",
    "    data_file = open(file,'r')\n",
    "    file_text = data_file.readlines() \n",
    "    num_frames = len(file_text)\n",
    "    num_framesets = int((num_frames - num_steps)/(num_steps*(1-overlap)))+1\n",
    "    data_file.close\n",
    "    file_name = \"datapoint_\" + str(count) + \"_testvid_\" + str(date.today()) + \".txt\"\n",
    "    x_file = open(file_name, 'a')\n",
    "    for frameset in range(0, num_framesets):\n",
    "        start = int(frameset*num_steps*(1-overlap))\n",
    "        for line in range(start,(start+num_steps)):\n",
    "            x_file.write(file_text[line])\n",
    "    x_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
